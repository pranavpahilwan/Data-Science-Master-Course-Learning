{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db7a81bd-f022-4ea4-9b78-67d8306fa95b",
   "metadata": {},
   "source": [
    "# Naïve bayes-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f741a670-d9f8-4359-bf2f-f2a13be8fdd7",
   "metadata": {},
   "source": [
    "#### Q1. A company conducted a survey of its employees and found that 70% of the employees use the company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54479981-28c0-4ce1-9d7f-75e1439b223e",
   "metadata": {},
   "source": [
    "#### Ans.\n",
    "\n",
    "P(H) = 0.7, since 70% of the employees use the health insurance plan.\n",
    "\n",
    "P(S|H) = 0.4, since 40% of the employees who use the health insurance plan are smokers.\n",
    "\n",
    "Assuming total number of smokers in the organisation to be 15%\n",
    "\n",
    "P(S) = 0.15\n",
    "\n",
    "P(H|S) = P(S|H)*P(H)/P(S)\n",
    "\n",
    "P(H|S) = 0.4*0.7/0.15\n",
    "\n",
    "P(H|S) = 1.8666666666666665"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a8f7967-9e92-4f0d-bdd6-bfcba83f875e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8666666666666665"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4*0.7/0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c94ec67-4c31-4bf4-af1e-63f567e21f52",
   "metadata": {},
   "source": [
    ".'.   Hence Probability that an employee is smoker given that he/she uses health insurance plan is 186%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7acfeb5-0d83-448b-9f9f-ff1b2e3bb5fb",
   "metadata": {},
   "source": [
    "#### Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8ceb1d-47ea-4497-8862-831879645937",
   "metadata": {},
   "source": [
    "#### Ans.\n",
    "Difference between Bernoulli, Multinomial and Gaussian Naive Bayes. Multinomial Naïve Bayes consider a feature vector where a given term represents the number of times it appears or very often i.e. frequency. On the other hand, Bernoulli is a binary algorithm used when the feature is present or not.\n",
    "\n",
    "- Bernoulli Naive Bayes:\n",
    "    - Assumes binary input data\n",
    "    - Represents each document as a binary vector\n",
    "    - Calculates likelihood probabilities based on presence/absence of features\t\n",
    "    - Suitable for problems focused on the presence or absence of features\n",
    "- Multinomial Naive Bayes\n",
    "    - Assumes count input data\n",
    "    - Represents each document as a count vector\n",
    "    - Calculates likelihood probabilities based on frequency of features\n",
    "    - Suitable for problems focused on the frequency of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891eebce-3748-4069-b2b1-8578ad04805c",
   "metadata": {},
   "source": [
    "#### Q3. How does Bernoulli Naive Bayes handle missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfa61dc-c191-4da8-ae00-d9147177aba6",
   "metadata": {},
   "source": [
    "#### Ans. \n",
    "Bernoulli Naive Bayes is primarily designed to work with binary data, where each feature can take on one of two values: 0 (absent) or 1 (present). When it comes to handling missing values in Bernoulli Naive Bayes, there are a few approaches you can consider:\n",
    "\n",
    "1. Ignore Missing Values: One approach is to simply ignore instances with missing values. This means that if a particular instance has a missing value for a specific feature, you exclude that instance from the analysis involving that feature. However, this approach could lead to a loss of information and might not be ideal, especially if missing values are common.\n",
    "\n",
    "2. Imputation: Another approach is to impute missing values with a default value before applying Bernoulli Naive Bayes. This might involve filling in the missing value with either 0 (absent) or 1 (present) based on some reasonable assumption or rule. However, this could introduce bias into your data, especially if the missing values are not truly indicative of the absence or presence of the feature.\n",
    "\n",
    "3. Treat Missing as a Separate Category: Instead of ignoring or imputing missing values, you could treat the missing values as a separate category of the feature. This means creating a new category, say \"missing,\" and assigning it a binary value (0 or 1) as you would with the other categories. This approach allows you to explicitly model instances with missing values and incorporate them into your classification.\n",
    "\n",
    "4. Use Advanced Techniques: Depending on the complexity of your data and the problem you're working on, you might consider more advanced techniques for handling missing values, such as using probabilistic models or machine learning algorithms to predict missing values based on other features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cee91f-5c52-4316-9c9f-0f9442e544b4",
   "metadata": {},
   "source": [
    "#### Q4. Can Gaussian Naive Bayes be used for multi-class classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff20d21d-8f6c-4abf-b5d1-6d47267aca85",
   "metadata": {},
   "source": [
    "#### Ans.\n",
    "Yes, Gaussian Naive Bayes can indeed be used for multi-class classification tasks. Gaussian Naive Bayes is a variant of the Naive Bayes algorithm that assumes that the features in your dataset follow a Gaussian (normal) distribution. It's particularly well-suited for continuous data where the values of features are real numbers.\n",
    "\n",
    "In the context of multi-class classification, Gaussian Naive Bayes extends naturally to handle multiple classes. The algorithm calculates the probabilities for each class based on the Gaussian distribution of feature values for each class. When you have more than two classes, the algorithm computes the probabilities for each class independently and then assigns the class with the highest probability as the predicted class.\n",
    "\n",
    "Here's how Gaussian Naive Bayes can be used for multi-class classification:\n",
    "\n",
    "1. Training:\n",
    "\n",
    "    - For each class, calculate the mean and standard deviation of each feature's values among the instances belonging to that class.\n",
    "    - You'll also need the prior probabilities of each class, which can be calculated based on the proportions of instances in each class.\n",
    "2. Prediction:\n",
    "\n",
    "    - Given a new instance with feature values, calculate the conditional probability of the instance belonging to each class using the Gaussian probability density function for each feature in each class.\n",
    "    - Multiply the conditional probabilities for all features to get the probability of the instance belonging to each class.\n",
    "    - The class with the highest probability is predicted as the class for the new instance.\n",
    "    \n",
    "Gaussian Naive Bayes is commonly used when the distribution of feature values for each class is approximately Gaussian, or at least can be reasonably approximated as such. However, keep in mind that the assumption of independence between features might not hold true in all cases, and the algorithm might not perform well if the data violates these assumptions significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae4b6db-0a88-4728-8a53-ab3ae22506d5",
   "metadata": {},
   "source": [
    "#### Q5. Assignment:\n",
    "- Data preparation:\n",
    "    - Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/ datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message is spam or not based on several input features.\n",
    "\n",
    "- Implementation:\n",
    "    - Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the dataset. You should use the default hyperparameters for each classifier.\n",
    "- Results:\n",
    "    - Report the following performance metrics for each classifier:\n",
    "    - Accuracy\n",
    "    - Precision\n",
    "    - Recall\n",
    "    - F1 score\n",
    "- Discussion:\n",
    "    - Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that i the case? Are there any limitations of Naive Bayes that you observed?\n",
    "- Conclusion:\n",
    "    - Summarise your findings and provide some suggestions for future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f844978-e7b0-495b-87ca-a91aafb8e637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8e24fda-d2bd-4a6d-8671-c2e7e748a836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  \n",
       "0                     0.627   50  \n",
       "1                     0.351   31  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate features and labels\n",
    "X = data.drop(columns=['Outcome'])\n",
    "y = data['Outcome']\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16cd6551-e29a-4dda-9636-f5476a5d2296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "763    0\n",
       "764    0\n",
       "765    0\n",
       "766    1\n",
       "767    0\n",
       "Name: Outcome, Length: 768, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a96eeb48-650f-44e3-8346-d5d6bb7a5783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2447219d-1dff-4792-a9c0-e22e0e5c4dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb_scores = cross_val_score(bnb, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c2d5062-e5e8-4ec8-a508-e566255a1497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(force_alpha=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(force_alpha=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB(force_alpha=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB(force_alpha=True)\n",
    "clff=clf.fit(X>0, y)\n",
    "clff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d54279ac-4ac1-409b-928c-d618ff4e9ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb_scores = cross_val_score(gnb, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446754ca-585a-44d5-92b4-7d737211637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dc66d0-c400-4b3b-9ecf-9f9ab49ec8f8",
   "metadata": {},
   "source": [
    "\tmodels\tcross_val_score_mean\n",
    "0\t  Gaussian\t  0.805719\n",
    "\n",
    "1\t  Bernoulli\t  0.849218\n",
    "\n",
    "2\t  Multinomial\t  0.720911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7c6a56-1027-4485-88e1-55802806ef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560a8396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
